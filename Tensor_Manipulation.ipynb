{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7GHDPQqeo7bD"
      ],
      "authorship_tag": "ABX9TyMJ9ID2POV2sd41e7W6ta+K"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## This is just a practice notebook where I manipulate tensors and experiment with different data types. Basically i'm fiddling around in the data pre-processing stage."
      ],
      "metadata": {
        "id": "ho1Wi0wPoxbz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Working with Images"
      ],
      "metadata": {
        "id": "7GHDPQqeo7bD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An image is represented as a collection of scalars arranged in a regular grid with a\n",
        "height and a width (in pixels). We might have a single scalar per grid point (the\n",
        "pixel), which would be represented as a grayscale image; or multiple scalars per grid\n",
        "point, which would typically represent different colors"
      ],
      "metadata": {
        "id": "VU96V6Y4pbkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio as im\n",
        "\n",
        "img_arr = im.imread('oppie.jpeg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmJJZ0F7qKjc",
        "outputId": "81c7ccb7-520f-4f5d-a54a-a9e67a2a2e67"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b6da11ef2a94>:3: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  img_arr = im.imread('oppie.jpeg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_arr.shape # the output is in the form of H x W x C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CddsD9xnrL-l",
        "outputId": "2e4ed370-5411-4d12-cdbb-e1c7f1741828"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2910, 5174, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# note that the proper layout for image arrays is C x H x W for PyTorch. We need to convert the images into that if required."
      ],
      "metadata": {
        "id": "t42uVWAQrO9L"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "img = torch.from_numpy(img_arr)\n",
        "out = img.permute(2,0,1) #inplace operation\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqJzQh2Mr3Zl",
        "outputId": "71ce2844-3dc2-4222-c465-df12585b3fa4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2910, 5174])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 3\n",
        "batch = torch.zeros(batch_size,6)"
      ],
      "metadata": {
        "id": "3kUP3PYysQGl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_dir = 'oppie_img_data/'\n",
        "filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1] == '.png']\n",
        "\n",
        "for i, filename in enumerate(filenames):\n",
        "  img_arr = im.imread(os.path.join(data_dir,filename))\n",
        "  img_t = torch.from_numpy(img_arr)\n",
        "  img_t = img_t.permute(2,0,1)\n",
        "  img_t = img_t[:3]\n",
        "  batch[i] = img_t"
      ],
      "metadata": {
        "id": "i37J-d-rwtn1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with Tabular Data"
      ],
      "metadata": {
        "id": "lNpTHuqQM7xT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " PyTorch tensors, on the other hand, are homogeneous. Information in PyTorch is\n",
        "typically encoded as a number, typically floating-point (though integer types and\n",
        "Boolean are supported as well). This numeric encoding is deliberate, since neural\n",
        "networks are mathematical entities that take real numbers as inputs and produce real\n",
        "numbers as output through successive application of matrix multiplications and\n",
        "nonlinear functions."
      ],
      "metadata": {
        "id": "5CObauvoNB4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "wine_path = 'winequality-white.csv'"
      ],
      "metadata": {
        "id": "eHjGAkk1NIi4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of pandas, let's import this using numpy"
      ],
      "metadata": {
        "id": "bFYUW6tTOUpr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "wine_num =  np.loadtxt(wine_path,dtype = np.float32, delimiter = ';',skiprows = 1)"
      ],
      "metadata": {
        "id": "taKm23UDOZjS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine_num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIktlNAfOd-a",
        "outputId": "a51e9b5e-24aa-4e15-cca6-f67c16660742"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
              "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
              "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
              "       ...,\n",
              "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
              "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
              "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wineq = torch.from_numpy(wine_num)"
      ],
      "metadata": {
        "id": "iTN3mXcIOxXL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wineq.type, wineq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G5r_hKYPe7p",
        "outputId": "191ad1dd-1d9b-4610-c560-82f1828d7290"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<function Tensor.type>, torch.Size([4898, 12]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = wineq[:,:-1]\n",
        "data, data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULUXH2oIPhKa",
        "outputId": "552654a6-92e7-4ff0-d771-9b5d632f7225"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 7.0000,  0.2700,  0.3600,  ...,  3.0000,  0.4500,  8.8000],\n",
              "         [ 6.3000,  0.3000,  0.3400,  ...,  3.3000,  0.4900,  9.5000],\n",
              "         [ 8.1000,  0.2800,  0.4000,  ...,  3.2600,  0.4400, 10.1000],\n",
              "         ...,\n",
              "         [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
              "         [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
              "         [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]]),\n",
              " torch.Size([4898, 11]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = wineq[:,-1]\n",
        "target, target.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rBEp6b1Q0ZS",
        "outputId": "4a9cefd6-a649-4069-951f-d48958d1977a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([6., 6., 6.,  ..., 6., 7., 6.]), torch.Size([4898]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uAb5q5QBQ5IC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}