{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7GHDPQqeo7bD"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOoVMqvrLESc3d4aCxTW7T9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikxlvii/pytorch/blob/main/Tensor_Manipulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This is just a practice notebook where I manipulate tensors and experiment with different data types. Basically i'm fiddling around in the data pre-processing stage."
      ],
      "metadata": {
        "id": "ho1Wi0wPoxbz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with Images"
      ],
      "metadata": {
        "id": "7GHDPQqeo7bD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An image is represented as a collection of scalars arranged in a regular grid with a\n",
        "height and a width (in pixels). We might have a single scalar per grid point (the\n",
        "pixel), which would be represented as a grayscale image; or multiple scalars per grid\n",
        "point, which would typically represent different colors"
      ],
      "metadata": {
        "id": "VU96V6Y4pbkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio as im\n",
        "\n",
        "img_arr = im.imread('oppie.jpeg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmJJZ0F7qKjc",
        "outputId": "81c7ccb7-520f-4f5d-a54a-a9e67a2a2e67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b6da11ef2a94>:3: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  img_arr = im.imread('oppie.jpeg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_arr.shape # the output is in the form of H x W x C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CddsD9xnrL-l",
        "outputId": "2e4ed370-5411-4d12-cdbb-e1c7f1741828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2910, 5174, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# note that the proper layout for image arrays is C x H x W for PyTorch. We need to convert the images into that if required."
      ],
      "metadata": {
        "id": "t42uVWAQrO9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "img = torch.from_numpy(img_arr)\n",
        "out = img.permute(2,0,1) #inplace operation\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqJzQh2Mr3Zl",
        "outputId": "71ce2844-3dc2-4222-c465-df12585b3fa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2910, 5174])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 3\n",
        "batch = torch.zeros(batch_size,6)"
      ],
      "metadata": {
        "id": "3kUP3PYysQGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_dir = 'oppie_img_data/'\n",
        "filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1] == '.png']\n",
        "\n",
        "for i, filename in enumerate(filenames):\n",
        "  img_arr = im.imread(os.path.join(data_dir,filename))\n",
        "  img_t = torch.from_numpy(img_arr)\n",
        "  img_t = img_t.permute(2,0,1)\n",
        "  img_t = img_t[:3]\n",
        "  batch[i] = img_t"
      ],
      "metadata": {
        "id": "i37J-d-rwtn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with Tabular Data"
      ],
      "metadata": {
        "id": "lNpTHuqQM7xT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " PyTorch tensors, on the other hand, are homogeneous. Information in PyTorch is\n",
        "typically encoded as a number, typically floating-point (though integer types and\n",
        "Boolean are supported as well). This numeric encoding is deliberate, since neural\n",
        "networks are mathematical entities that take real numbers as inputs and produce real\n",
        "numbers as output through successive application of matrix multiplications and\n",
        "nonlinear functions."
      ],
      "metadata": {
        "id": "5CObauvoNB4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "wine_path = 'winequality-white.csv'"
      ],
      "metadata": {
        "id": "eHjGAkk1NIi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of pandas, let's import this using numpy"
      ],
      "metadata": {
        "id": "bFYUW6tTOUpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "wine_num =  np.loadtxt(wine_path,dtype = np.float32, delimiter = ';',skiprows = 1)"
      ],
      "metadata": {
        "id": "taKm23UDOZjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine_num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIktlNAfOd-a",
        "outputId": "a51e9b5e-24aa-4e15-cca6-f67c16660742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
              "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
              "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
              "       ...,\n",
              "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
              "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
              "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wineq = torch.from_numpy(wine_num)"
      ],
      "metadata": {
        "id": "iTN3mXcIOxXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wineq.type, wineq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G5r_hKYPe7p",
        "outputId": "191ad1dd-1d9b-4610-c560-82f1828d7290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<function Tensor.type>, torch.Size([4898, 12]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = wineq[:,:-1]\n",
        "data, data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULUXH2oIPhKa",
        "outputId": "552654a6-92e7-4ff0-d771-9b5d632f7225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 7.0000,  0.2700,  0.3600,  ...,  3.0000,  0.4500,  8.8000],\n",
              "         [ 6.3000,  0.3000,  0.3400,  ...,  3.3000,  0.4900,  9.5000],\n",
              "         [ 8.1000,  0.2800,  0.4000,  ...,  3.2600,  0.4400, 10.1000],\n",
              "         ...,\n",
              "         [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
              "         [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
              "         [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]]),\n",
              " torch.Size([4898, 11]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = wineq[:,-1]\n",
        "target, target.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rBEp6b1Q0ZS",
        "outputId": "4a9cefd6-a649-4069-951f-d48958d1977a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([6., 6., 6.,  ..., 6., 7., 6.]), torch.Size([4898]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with Text"
      ],
      "metadata": {
        "id": "QY6933KOwd26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a section which involves NLP and the process is quite simple.\n",
        "\n",
        "1. Encoding Characters: First we will split the text into individual lines then create a tensor to contain the individual character ASCII data. The maximum in ASCII is 128. After that we will individual allocate the characters to the tensor with their ASCII notation.\n",
        "\n",
        "2. Encoding Words: To encode words, we have to establish a vocabulary and encode words along the rows of our tensor. There's a better way to do this other than encoding which is known as embedding which I'll do after this. In this method, we first create a function to clean the words (remove punctuation). Then we choose a line and take out all the words from it to make a word_list. Then we enumerate all of the words in the text and only add the ones in the tensor which we took out in the word_list."
      ],
      "metadata": {
        "id": "ECmcg7bc0qTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "qzRWXcZ9zfE_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('jane_austen.txt') as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "Ho9ydluuwgBj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the text into lines\n",
        "\n",
        "lines = text.split('\\n')\n",
        "line = lines[200]\n",
        "line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "irwu44m_xbni",
        "outputId": "5a772715-dde7-42bf-896e-c12a088c1d8f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'“Impossible, Mr. Bennet, impossible, when I am not acquainted with him'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding characters\n",
        "letter_t = torch.zeros(len(line),128)"
      ],
      "metadata": {
        "id": "tJwY3JqszPbp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "letter_t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXBsvG0yzW-E",
        "outputId": "89c1a7b9-0581-41e3-de0e-df06415cd56d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([70, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, letter in enumerate(line.lower().strip()):\n",
        "  letter_index = ord(letter) if ord(letter) < 128 else 0\n",
        "  letter_t[i][letter_index] = 1"
      ],
      "metadata": {
        "id": "-aCFPzQ3zlWg"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding words\n",
        "\n",
        "def clean_words(input_str):\n",
        "  punctuation = '.,;:\"!?”“_-'\n",
        "  word_list = input_str.lower().replace('\\n',' ').split()\n",
        "  word_list = [word.strip(punctuation) for word in word_list]\n",
        "  return word_list"
      ],
      "metadata": {
        "id": "Bh2vF9cc0YlJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_line = clean_words(line)\n",
        "line,words_in_line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-Tp0vRI0cH5",
        "outputId": "aaeb747c-9543-4faf-ac8e-0a651aec776c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('“Impossible, Mr. Bennet, impossible, when I am not acquainted with him',\n",
              " ['impossible',\n",
              "  'mr',\n",
              "  'bennet',\n",
              "  'impossible',\n",
              "  'when',\n",
              "  'i',\n",
              "  'am',\n",
              "  'not',\n",
              "  'acquainted',\n",
              "  'with',\n",
              "  'him'])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = sorted(set(clean_words(text)))\n",
        "len(word_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHwuyRaXAHSb",
        "outputId": "5f107c66-a4ba-4d69-b596-032bcb6ae2a3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7261"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2index_dict = {word : i for (i,word) in enumerate(word_list)}"
      ],
      "metadata": {
        "id": "U0_z5Wg3A5r7"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_t = torch.zeros(len(words_in_line), len(word2index_dict))\n",
        "for i, word in enumerate(words_in_line):\n",
        "  word_index = word2index_dict[word]\n",
        "  word_t[i][word_index] = 1\n",
        "  print('{:2} {:4} {}'.format(i, word_index, word))\n",
        "  print(word_t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBj9aST9BTsh",
        "outputId": "af46aeed-e790-4ffc-fb51-69981a1cd7e0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0 3394 impossible\n",
            "torch.Size([11, 7261])\n",
            " 1 4305 mr\n",
            "torch.Size([11, 7261])\n",
            " 2  813 bennet\n",
            "torch.Size([11, 7261])\n",
            " 3 3394 impossible\n",
            "torch.Size([11, 7261])\n",
            " 4 7078 when\n",
            "torch.Size([11, 7261])\n",
            " 5 3315 i\n",
            "torch.Size([11, 7261])\n",
            " 6  415 am\n",
            "torch.Size([11, 7261])\n",
            " 7 4436 not\n",
            "torch.Size([11, 7261])\n",
            " 8  239 acquainted\n",
            "torch.Size([11, 7261])\n",
            " 9 7148 with\n",
            "torch.Size([11, 7261])\n",
            "10 3215 him\n",
            "torch.Size([11, 7261])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The problem with one-hot encoding when the number of items to encode is too large. We just encoded 7000 items, and if there's a better way to do this then why not. So now, we will move onto embeddings instead of encoding."
      ],
      "metadata": {
        "id": "5R19179zD164"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n40xyifqEECh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}